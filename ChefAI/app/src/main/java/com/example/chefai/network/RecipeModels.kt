package com.example.chefai.network

import com.google.gson.annotations.SerializedName

// Using Gson annotations for potential field name differences if needed,
// although standard names usually work for OpenAI's API.

// --- Request Models ---

/**
 * Represents the overall request body sent to the OpenAI Chat Completions API.
 * model: Specifies the AI model to use (e.g., "gpt-3.5-turbo").
 * messages: A list containing the conversation history (system prompt, user prompt, etc.).
 * temperature: Controls the creativity/randomness of the output (optional, defaults often okay).
 */
data class ChatRequest(
    val model: String = "gpt-4o-mini", // Or "gpt-4o-mini", "gpt-4", etc. Check OpenAI docs for models
    val messages: List<ChatMessage>,
    val temperature: Double = 0.7 // 0.0 = deterministic, ~0.7 = balanced, >1.0 = very creative
    // Add other parameters like 'max_tokens' if needed
)

/**
 * Represents a single message within the conversation history.
 * role: Indicates who sent the message ("system", "user", or "assistant").
 * content: The actual text content of the message.
 */
data class ChatMessage(
    val role: String,
    val content: String
)

// --- Response Models ---

/**
 * Represents the overall structure of the response from the OpenAI Chat Completions API.
 */
data class ChatResponse(
    val id: String?,
    @SerializedName("object") val objectType: String?, // "object" is a keyword, rename field
    val created: Long?,
    val model: String?,
    val choices: List<Choice>?, // The list of possible completions generated by the AI
    val usage: Usage? // Information about token usage
    // You could add an 'error' field here to map detailed API error responses if needed
    // val error: ApiError?
)

/**
 * Represents one of the completion choices provided by the AI. Usually, you'll use the first one.
 * message: Contains the actual response message from the AI assistant.
 * finish_reason: Indicates why the completion ended (e.g., "stop", "length").
 */
data class Choice(
    val index: Int?,
    val message: ResponseMessage?,
    @SerializedName("finish_reason") val finishReason: String?
)

/**
 * Represents the message content generated by the AI assistant.
 * role: Should typically be "assistant".
 * content: The recipe text (hopefully structured as requested in the prompt).
 */
data class ResponseMessage(
    val role: String?,
    val content: String?
)

/**
 * Provides details on the number of tokens used for the API call.
 */
data class Usage(
    @SerializedName("prompt_tokens") val promptTokens: Int?,
    @SerializedName("completion_tokens") val completionTokens: Int?,
    @SerializedName("total_tokens") val totalTokens: Int?
)

/**
 * Represents the request body sent to the OpenAI Image Generation API (DALL-E).
 * model: Specifies the model (e.g., "dall-e-3").
 * prompt: The text description used to generate the image (this will come from your Recipe's imagePrompt).
 * n: The number of images to generate (usually 1).
 * size: The desired size of the generated image (e.g., "1024x1024"). DALL-E 3 supports specific sizes.
 * quality: Optional quality setting ("standard" or "hd").
 * response_format: Optional format ("url" or "b64_json"). "url" is usually easier.
 * style: Optional style ("vivid" or "natural").
 */
data class DallERequest(
    val model: String = "dall-e-2",
    val prompt: String,
    val n: Int = 1, // Generate one image
    val size: String = "1024x1024", // Standard size for DALL-E 3
    @SerializedName("response_format") val responseFormat: String = "url", // Get a URL back
    // val style: String = "vivid" // Optional style
)

// --- DALL-E 3 Response Models --- ADD THIS SECTION ---

/**
 * Represents the overall response from the OpenAI Image Generation API.
 */
data class DallEResponse(
    val created: Long?,
    val data: List<ImageResult>?
    // Add error field if needed
    // val error: ApiError?
)

/**
 * Represents the result for a single generated image.
 * url: The URL where the generated image can be accessed (expires after some time).
 * b64_json: Alternatively, the image data encoded as Base64 JSON (if requested).
 * revised_prompt: OpenAI might revise your prompt for safety/clarity; this shows the revised version.
 */
data class ImageResult(
    val url: String?,
    @SerializedName("b64_json") val b64Json: String?,
    @SerializedName("revised_prompt") val revisedPrompt: String?
)